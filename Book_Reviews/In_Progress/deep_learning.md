## Deep Learning
### Introduction to my experience with this book
+This is an introductory book that is more accessible and provides a high level introduction to complex topics 


### What's different
+ A book that is fully focused on deep learning and ensures new readers to machine learning can keep up with the content

### What else is good
+

### What can be improved
+

## Brief personal summary of the book and things that I've learned from the book
+ Chapter 1 - Introduction - Structure of basic deep learning models and motivations

+ Chapter 2 (Part 1) - Linear Alegebra - required for deep learning. For deep learning this is around an A level standard and not too difficult.

+ Chapter 3 - Probability and Information Theory - Introduction to basic probability and statistical concepts which spans from A level standards to more complex concepts. 
    + Basic probability concepts include the multinoulli distribution, the Gaussian distribution, Dirac Delta distribution, Gaussian Mixtures and Bayes' rule. 
    + Basic information theory include Shannon information, KL divergence / Cross-entropy, (a commonly used cost for multinoulli distributions).
    + Basic introduction to graphical models - The book misses a focus on the independence assumptions in directed models and considers 'random' to be a sufficient replacement.

+ Chapter 1 - Breakdown
+ Chapter 1 - Breakdown
+ Chapter 1 - Breakdown
+ Chapter 1 - Breakdown
+ Chapter 1 - Breakdown
+ Chapter 1 - Breakdown
+ Chapter 1 - Breakdown



### Things I need to revisit



