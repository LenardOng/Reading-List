Machine Learning: An Algorithmic Perspective
	Practical introduction for those wanting to understand the intuition between popular tools such SciKit or Numpy as well as deep learning frameworks like Keras, Tensorflow and Caffe. 
	Useful in giving code that works. Much of machine learning involves writing code to process large amounts of data. Focus on O complexity and providing easy to understand code is very beneficial to the aspiring machine learning enthusiast. Inclusion of many different types of dimensionality reduction whilst the most commonly heard ones are just PCA and ICA.
	

	Maybe more explanation in applications, emphasising the distinction and uses between the four major machine learning problems, dimensionality reduction, regression, classification and clustering.
	Explanation of various optimization techniques
	
	Exploration vs Exploitation - Basic definitions and a few algorithms. Good introduction to reinforcement learning
	
	Bayesian networks
	Kalman filter makes a strange appearance
	
	Relook at:
	HMM
	Viterbi
	Particle Filter
	Hopsfield
	Boltzmann machine
	Contrastive Divergence Learning
	
Information Theory, Inference and Algorithms
	Definition of probability 
	Very practical with many examples with accompanying solutions to assist learning
	Good reminder of Shannon Information
	Easy to get lost in the maths unless working through exercises
    
The Elements of Statistical Learning
	Very difficult book
	Emphasis on the creation of a separating hyperplane
	
Bayesian Artificial Intelligence
	Historical look into the different probability theories
	Learning machine focus on Bayesian Networks
    Common mistakes is decent
    Practical construction of a BNN
	A lot of fluff - History and path, lead up to AI winter
	Bias variance trade-off
	Late on information theory
	
Neural Networks and Learning Machines
	Not very useful a book for learning
	
	